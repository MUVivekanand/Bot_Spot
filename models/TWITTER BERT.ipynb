{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cae42c3-f1fe-45c5-b2b8-2c4dccd93e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs Available: 1\n",
      "GPU 0: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get the number of GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(f\"Number of GPUs Available: {num_gpus}\")\n",
    "\n",
    "# List all GPU names if GPUs are available\n",
    "if num_gpus > 0:\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPUs available in the system.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fb4b2dc-e7a2-4bc9-991f-9b04eb546a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas in c:\\users\\project\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\project\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\project\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\project\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\project\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\project\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f7848a-7749-49c6-bcb7-32a86ebb740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Mention Count</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Bot Label</th>\n",
       "      <th>Location</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132131</td>\n",
       "      <td>flong</td>\n",
       "      <td>Station activity person against natural majori...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>2353</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Adkinston</td>\n",
       "      <td>2020-05-11 15:29:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289683</td>\n",
       "      <td>hinesstephanie</td>\n",
       "      <td>Authority research natural life material staff...</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>9617</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanderston</td>\n",
       "      <td>2022-11-26 05:18:10</td>\n",
       "      <td>both live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>779715</td>\n",
       "      <td>roberttran</td>\n",
       "      <td>Manage whose quickly especially foot none to g...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4363</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Harrisonfurt</td>\n",
       "      <td>2022-08-08 03:16:54</td>\n",
       "      <td>phone ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>696168</td>\n",
       "      <td>pmason</td>\n",
       "      <td>Just cover eight opportunity strong policy which.</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>2242</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Martinezberg</td>\n",
       "      <td>2021-08-14 22:27:05</td>\n",
       "      <td>ever quickly new I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704441</td>\n",
       "      <td>noah87</td>\n",
       "      <td>Animal sign six data good or.</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>8438</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Camachoville</td>\n",
       "      <td>2020-04-13 21:24:21</td>\n",
       "      <td>foreign mention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID        Username                                              Tweet  \\\n",
       "0   132131           flong  Station activity person against natural majori...   \n",
       "1   289683  hinesstephanie  Authority research natural life material staff...   \n",
       "2   779715      roberttran  Manage whose quickly especially foot none to g...   \n",
       "3   696168          pmason  Just cover eight opportunity strong policy which.   \n",
       "4   704441          noah87                      Animal sign six data good or.   \n",
       "\n",
       "   Retweet Count  Mention Count  Follower Count  Verified  Bot Label  \\\n",
       "0             85              1            2353     False          1   \n",
       "1             55              5            9617      True          0   \n",
       "2              6              2            4363      True          0   \n",
       "3             54              5            2242      True          1   \n",
       "4             26              3            8438     False          1   \n",
       "\n",
       "       Location           Created At            Hashtags  \n",
       "0     Adkinston  2020-05-11 15:29:50                 NaN  \n",
       "1    Sanderston  2022-11-26 05:18:10           both live  \n",
       "2  Harrisonfurt  2022-08-08 03:16:54         phone ahead  \n",
       "3  Martinezberg  2021-08-14 22:27:05  ever quickly new I  \n",
       "4  Camachoville  2020-04-13 21:24:21     foreign mention  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"E:\\bot_detection_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5e4686-6a40-409f-b14e-de240260fe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "759e08f9-db78-4683-80ca-922a8e8dcf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9803f6e-d1f9-41dd-acf0-f011b3c06377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tweet\"] = df[\"Tweet\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f414ea91-d0e8-4514-a642-9bfec353e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "bots = df[df[\"Bot Label\"] == 1]\n",
    "humans = df[df[\"Bot Label\"] == 0]\n",
    "\n",
    "# Ensure both have equal count (12,500 each)\n",
    "bots_sampled = bots.sample(n=5000, random_state=42)\n",
    "humans_sampled = humans.sample(n=5000, random_state=42)\n",
    "\n",
    "# Combine into a balanced dataset\n",
    "df_balanced = pd.concat([bots_sampled, humans_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check new dataset size\n",
    "df_balanced.to_csv(r\"E:\\balanced_bot_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "821f0fdf-85a5-4880-8b2b-4e85af318552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e7d5af-75da-4a3f-857c-3dd8ef337fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in c:\\users\\project\\anaconda3\\lib\\site-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\project\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\project\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\project\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\project\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\project\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\project\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\project\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\project\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1022d813-a282-4f31-beb5-825a3b7e8c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "pipe = pipeline(\"fill-mask\", model=\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9460743-d0e9-4df6-977f-d1297558adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "distilbert_model = AutoModelForMaskedLM.from_pretrained(\"distilbert/distilbert-base-uncased\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7b91a8a-d78b-49a7-99a0-60f66a629c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForMaskedLM(\n",
       "  (activation): GELUActivation()\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vocab_transform): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (vocab_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (vocab_projector): Linear(in_features=768, out_features=30522, bias=True)\n",
       "  (mlm_loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4077afde-6874-444d-9cf2-c43927f48eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_bert_embeddings_batch(text_list, batch_size=32):\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(text_list), batch_size), desc=\"Processing Batches on GPU\"):\n",
    "        batch = text_list[i : i + batch_size]  # Get batch of tweets\n",
    "        \n",
    "        # ✅ Tokenize & Move Inputs to GPU\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():  # No gradients needed for inference (faster)\n",
    "            outputs = distilbert_model(**inputs)\n",
    "\n",
    "        # ✅ Extract CLS token embedding, Move to CPU only after computation\n",
    "        batch_embeddings = outputs[0][:, 0, :].squeeze().cpu().numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42434921-ba64-410b-a7b0-a2c9f1447542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches on GPU: 100%|█████████████████████████████████████████████████████| 313/313 [00:05<00:00, 62.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ BERT embeddings computed and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df_balanced[\"BERT_Embedding\"] = list(get_bert_embeddings_batch(df_balanced[\"Tweet\"].tolist()))\n",
    "\n",
    "# ✅ Save to CSV\n",
    "df_balanced.to_csv(r\"E:\\bert_embeddings_dataset.csv\", index=False)\n",
    "\n",
    "print(\"✅ BERT embeddings computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42b4ea3a-999a-436f-8909-60847053093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Mention Count</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Bot Label</th>\n",
       "      <th>Location</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>BERT_Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>652679</td>\n",
       "      <td>kayla00</td>\n",
       "      <td>cause wall treat dog for rock through nor follow</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>North Leonfurt</td>\n",
       "      <td>2022-04-19 09:42:22</td>\n",
       "      <td>church fire have site</td>\n",
       "      <td>[-7.431979, -7.3733125, -7.379997, -7.3138256,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>169154</td>\n",
       "      <td>lucaslauren</td>\n",
       "      <td>social hard something enough very unit pass ei...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>9596</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>West Amandafurt</td>\n",
       "      <td>2020-04-24 06:20:45</td>\n",
       "      <td>century interview stay</td>\n",
       "      <td>[-6.756239, -6.716732, -6.6539307, -6.67578, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295421</td>\n",
       "      <td>tylercooke</td>\n",
       "      <td>remember finish policy write trade other plan</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>6962</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>North William</td>\n",
       "      <td>2020-02-15 20:10:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-6.580943, -6.554112, -6.509034, -6.512717, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321577</td>\n",
       "      <td>kingstephanie</td>\n",
       "      <td>citizen stock figure surface probably their ma...</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>6333</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Jasonhaven</td>\n",
       "      <td>2020-05-16 15:03:58</td>\n",
       "      <td>throw ok Congress treatment</td>\n",
       "      <td>[-7.1368346, -7.0517673, -6.992747, -7.014969,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297166</td>\n",
       "      <td>hstark</td>\n",
       "      <td>sport north better black cold modern coach som...</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>6718</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Lake Matthew</td>\n",
       "      <td>2020-02-14 01:00:34</td>\n",
       "      <td>debate program past bag</td>\n",
       "      <td>[-6.5802073, -6.550487, -6.4497786, -6.4803257...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID       Username                                              Tweet  \\\n",
       "0   652679        kayla00   cause wall treat dog for rock through nor follow   \n",
       "1   169154    lucaslauren  social hard something enough very unit pass ei...   \n",
       "2   295421     tylercooke      remember finish policy write trade other plan   \n",
       "3   321577  kingstephanie  citizen stock figure surface probably their ma...   \n",
       "4   297166         hstark  sport north better black cold modern coach som...   \n",
       "\n",
       "   Retweet Count  Mention Count  Follower Count  Verified  Bot Label  \\\n",
       "0             95              2             197      True          0   \n",
       "1             67              0            9596     False          1   \n",
       "2             52              0            6962     False          1   \n",
       "3             90              2            6333      True          1   \n",
       "4             99              0            6718      True          1   \n",
       "\n",
       "          Location           Created At                     Hashtags  \\\n",
       "0   North Leonfurt  2022-04-19 09:42:22        church fire have site   \n",
       "1  West Amandafurt  2020-04-24 06:20:45       century interview stay   \n",
       "2    North William  2020-02-15 20:10:11                          NaN   \n",
       "3       Jasonhaven  2020-05-16 15:03:58  throw ok Congress treatment   \n",
       "4     Lake Matthew  2020-02-14 01:00:34      debate program past bag   \n",
       "\n",
       "                                      BERT_Embedding  \n",
       "0  [-7.431979, -7.3733125, -7.379997, -7.3138256,...  \n",
       "1  [-6.756239, -6.716732, -6.6539307, -6.67578, -...  \n",
       "2  [-6.580943, -6.554112, -6.509034, -6.512717, -...  \n",
       "3  [-7.1368346, -7.0517673, -6.992747, -7.014969,...  \n",
       "4  [-6.5802073, -6.550487, -6.4497786, -6.4803257...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cb361ee-805a-42f5-97a4-c6efb1bc4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced[\"Verified\"] = df_balanced[\"Verified\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b073848-1348-4222-9090-0ace487f96ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor is on: cuda:0\n",
      "y_train_tensor is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ Select structured features\n",
    "structured_features = [\"Retweet Count\", \"Mention Count\", \"Follower Count\", \"Verified\"]\n",
    "X_structured = df_balanced[structured_features].fillna(0).values  # Convert to NumPy array\n",
    "\n",
    "# ✅ Normalize Structured Features (StandardScaler runs on CPU)\n",
    "scaler = StandardScaler()\n",
    "X_structured = scaler.fit_transform(X_structured)\n",
    "\n",
    "# ✅ Convert BERT embeddings to NumPy array\n",
    "X_bert = np.vstack(df_balanced[\"BERT_Embedding\"].values)\n",
    "\n",
    "# ✅ Combine BERT Embeddings + Structured Features\n",
    "X_combined = np.hstack((X_bert, X_structured))\n",
    "\n",
    "# ✅ Target Variable (Bot Label)\n",
    "y = df_balanced[\"Bot Label\"].values\n",
    "\n",
    "# ✅ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Convert to Torch Tensors & Move to GPU (This avoids CPU processing delays)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32, device=\"cuda\")\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=\"cuda\")\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32, device=\"cuda\").unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32, device=\"cuda\").unsqueeze(1)\n",
    "\n",
    "# ✅ Check if tensors are on GPU\n",
    "print(f\"X_train_tensor is on: {X_train_tensor.device}\")  # Should print: cuda\n",
    "print(f\"y_train_tensor is on: {y_train_tensor.device}\")  # Should print: cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419ee24-8ac7-4a37-88e8-54264a47fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_structured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6798a5d3-512b-4f32-bdae-19f20b5daf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TwitterDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TwitterDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9362991-cb1a-43c4-979a-0e5583dc4d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/90], Loss: 49.2506\n",
      "Epoch [2/90], Loss: 49.8375\n",
      "Epoch [3/90], Loss: 49.8375\n",
      "Epoch [4/90], Loss: 49.8375\n",
      "Epoch [5/90], Loss: 49.8375\n",
      "Epoch [6/90], Loss: 49.8375\n",
      "Epoch [7/90], Loss: 49.8375\n",
      "Epoch [8/90], Loss: 49.8375\n",
      "Epoch [9/90], Loss: 49.8375\n",
      "Epoch [10/90], Loss: 49.8375\n",
      "Epoch [11/90], Loss: 49.8375\n",
      "Epoch [12/90], Loss: 49.8375\n",
      "Epoch [13/90], Loss: 49.8375\n",
      "Epoch [14/90], Loss: 49.8375\n",
      "Epoch [15/90], Loss: 49.8375\n",
      "Epoch [16/90], Loss: 49.8375\n",
      "Epoch [17/90], Loss: 49.8375\n",
      "Epoch [18/90], Loss: 49.8375\n",
      "Epoch [19/90], Loss: 49.8375\n",
      "Epoch [20/90], Loss: 49.8375\n",
      "Epoch [21/90], Loss: 49.8375\n",
      "Epoch [22/90], Loss: 49.8375\n",
      "Epoch [23/90], Loss: 49.8375\n",
      "Epoch [24/90], Loss: 49.8375\n",
      "Epoch [25/90], Loss: 49.8375\n",
      "Epoch [26/90], Loss: 49.8375\n",
      "Epoch [27/90], Loss: 49.8375\n",
      "Epoch [28/90], Loss: 49.8375\n",
      "Epoch [29/90], Loss: 49.8375\n",
      "Epoch [30/90], Loss: 49.8375\n",
      "Epoch [31/90], Loss: 49.8375\n",
      "Epoch [32/90], Loss: 49.8375\n",
      "Epoch [33/90], Loss: 49.8375\n",
      "Epoch [34/90], Loss: 49.8375\n",
      "Epoch [35/90], Loss: 49.8375\n",
      "Epoch [36/90], Loss: 49.8375\n",
      "Epoch [37/90], Loss: 49.8375\n",
      "Epoch [38/90], Loss: 49.8375\n",
      "Epoch [39/90], Loss: 49.8375\n",
      "Epoch [40/90], Loss: 49.8375\n",
      "Epoch [41/90], Loss: 49.8375\n",
      "Epoch [42/90], Loss: 49.8375\n",
      "Epoch [43/90], Loss: 49.8375\n",
      "Epoch [44/90], Loss: 49.8375\n",
      "Epoch [45/90], Loss: 49.8375\n",
      "Epoch [46/90], Loss: 49.8375\n",
      "Epoch [47/90], Loss: 49.8375\n",
      "Epoch [48/90], Loss: 49.8375\n",
      "Epoch [49/90], Loss: 49.8375\n",
      "Epoch [50/90], Loss: 49.8375\n"
     ]
    }
   ],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "input_size = X_train.shape[1]\n",
    "model = MLPClassifier(input_size).to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train Model\n",
    "num_epochs = 90\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate Model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a7640-1ede-4ef6-8ed6-1e2a395b5f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9169b-778a-4468-8464-6927bb00ad9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
